{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This code uses an ANN to predict outcomes of AFL matches in 2018 based on player data from 2012-2017.'''\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afl = pd.read_csv('C:/path/to/your/csv/file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "afl = pd.read_csv('C:/Users/the_n/OneDrive/Documents/Coding/stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 63712 entries, 0 to 63711\n",
      "Data columns (total 37 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Team                    63712 non-null  object \n",
      " 1   Player                  63712 non-null  object \n",
      " 2   D.O.B                   63712 non-null  object \n",
      " 3   Height                  63712 non-null  int64  \n",
      " 4   Weight                  63712 non-null  int64  \n",
      " 5   Position                63712 non-null  object \n",
      " 6   Season                  63712 non-null  int64  \n",
      " 7   Round                   63712 non-null  object \n",
      " 8   Date                    63624 non-null  object \n",
      " 9   Score                   63624 non-null  float64\n",
      " 10  Margin                  63624 non-null  float64\n",
      " 11  WinLoss                 63624 non-null  object \n",
      " 12  Opposition              63624 non-null  object \n",
      " 13  Venue                   63624 non-null  object \n",
      " 14  Disposals               63712 non-null  int64  \n",
      " 15  Kicks                   63712 non-null  int64  \n",
      " 16  Marks                   63712 non-null  int64  \n",
      " 17  Handballs               63712 non-null  int64  \n",
      " 18  Goals                   63712 non-null  int64  \n",
      " 19  Behinds                 63712 non-null  int64  \n",
      " 20  Hitouts                 63712 non-null  int64  \n",
      " 21  Tackles                 63712 non-null  int64  \n",
      " 22  Rebound50s              63712 non-null  int64  \n",
      " 23  Inside50s               63712 non-null  int64  \n",
      " 24  Clearances              63712 non-null  int64  \n",
      " 25  Clangers                63712 non-null  int64  \n",
      " 26  FreesFor                63712 non-null  int64  \n",
      " 27  FreesAgainst            63712 non-null  int64  \n",
      " 28  BrownlowVotes           63712 non-null  int64  \n",
      " 29  ContendedPossessions    63712 non-null  int64  \n",
      " 30  UncontendedPossessions  63712 non-null  int64  \n",
      " 31  ContestedMarks          63712 non-null  int64  \n",
      " 32  MarksInside50           63712 non-null  int64  \n",
      " 33  OnePercenters           63712 non-null  int64  \n",
      " 34  Bounces                 63712 non-null  int64  \n",
      " 35  GoalAssists             63712 non-null  int64  \n",
      " 36  PercentPlayed           63712 non-null  int64  \n",
      "dtypes: float64(2), int64(26), object(9)\n",
      "memory usage: 18.0+ MB\n"
     ]
    }
   ],
   "source": [
    "afl.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "afl = afl.dropna(axis=0)\n",
    "afl = afl[afl['WinLoss'] != 'D']\n",
    "afl['D.O.B'] = pd.to_datetime(afl['D.O.B'])\n",
    "afl['Date'] = pd.to_datetime(afl['Date'])\n",
    "age_in_days = (afl['Date']-afl['D.O.B'])\n",
    "age_in_years = age_in_days.dt.days/365.2425\n",
    "afl['Age'] = age_in_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = afl.groupby(['Team','Season','Round','WinLoss','Opposition','Venue'])['Player'].apply(list).reset_index()\n",
    "grouped_data = grouped_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Adelaide', 2012, 'PF', 'L', 'Hawthorn', 'M.C.G.',\n",
       "       list(['Callinan, Ian', 'Dangerfield, Patrick', 'Doughty, Michael', 'Douglas, Richard', 'Henderson, Ricky', 'Jacobs, Sam', 'Johncock, Graham', 'Mackay, David', 'Otten, Andy', 'Petrenko, Jared', 'Porplyzia, Jason', 'Reilly, Brent', 'Rutten, Ben', 'Sloane, Rory', 'Smith, Brodie', 'Thompson, Luke', 'Thompson, Scott', 'Tippett, Kurt', 'Vince, Bernie', 'Walker, Taylor', 'Wright, Matthew', 'van Berlo, Nathan'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "ct1 = ColumnTransformer([('encoder',OneHotEncoder(),[3,4,5])], remainder='passthrough',sparse_threshold=0)\n",
    "grouped_data = ct1.fit_transform(grouped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0,\n",
       "       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 0.0, 0.0, 'Adelaide', 2012, 'PF',\n",
       "       list(['Callinan, Ian', 'Dangerfield, Patrick', 'Doughty, Michael', 'Douglas, Richard', 'Henderson, Ricky', 'Jacobs, Sam', 'Johncock, Graham', 'Mackay, David', 'Otten, Andy', 'Petrenko, Jared', 'Porplyzia, Jason', 'Reilly, Brent', 'Rutten, Ben', 'Sloane, Rory', 'Smith, Brodie', 'Thompson, Luke', 'Thompson, Scott', 'Tippett, Kurt', 'Vince, Bernie', 'Walker, Taylor', 'Wright, Matthew', 'van Berlo, Nathan'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = [x for x in grouped_data if x[43]<2018]\n",
    "test = [x for x in grouped_data if x[43]==2018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array([x[0] for x in training])\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_test = np.array([x[0] for x in test])\n",
    "y_test = y_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [1.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# player_stats is each players' average stats between 2012 and 2017.\n",
    "player_stats = afl[afl['Season'] < 2018].groupby('Player',sort=False).mean()\n",
    "player_stats = player_stats.reset_index()\n",
    "player_stats = player_stats.drop(['Height','Weight','Season','BrownlowVotes','Score','Margin'],axis=1)\n",
    "player_stats = player_stats.to_numpy()\n",
    "\n",
    "# Player average stats for 2018\n",
    "player_stats_2018 = afl[afl['Season'] == 2018].groupby('Player',sort=False).mean()\n",
    "player_stats_2018 = player_stats_2018.reset_index()\n",
    "player_stats_2018 = player_stats_2018.drop(['Height','Weight','Season','BrownlowVotes','Score','Margin'],axis=1)\n",
    "player_stats_2018 = player_stats_2018.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Atkins, Rory', 19.910714285714285, 11.053571428571429,\n",
       "       4.357142857142857, 8.857142857142858, 0.4642857142857143,\n",
       "       0.35714285714285715, 0.10714285714285714, 1.8928571428571428,\n",
       "       1.8392857142857142, 3.482142857142857, 1.8392857142857142,\n",
       "       2.607142857142857, 0.4107142857142857, 0.75, 6.142857142857143,\n",
       "       13.982142857142858, 0.30357142857142855, 0.3392857142857143,\n",
       "       1.2321428571428572, 0.7678571428571429, 0.625, 78.32142857142857,\n",
       "       22.247987882805838], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player_stats[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1145"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(player_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include opposition and venue in features\n",
    "opp_teams_train = np.array([x[2:42] for x in training])\n",
    "opp_teams_test = np.array([x[2:42] for x in test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "       0.0], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opp_teams_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [0]*len(training)\n",
    "for i in range(0,len(training)):\n",
    "    player_list = []\n",
    "    j = 0\n",
    "    for j in range(0,len(player_stats)):\n",
    "        if player_stats[j][0] in training[i][-1]:\n",
    "            player_list.append(player_stats[j][1:])\n",
    "    X_train[i] = player_list\n",
    "    \n",
    "X_train = [np.concatenate(x) for x in X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([20.346774193548388, 12.725806451612904, 3.4919354838709675,\n",
       "       7.620967741935484, 0.6693548387096774, 0.5645161290322581,\n",
       "       0.06451612903225806, 3.870967741935484, 1.314516129032258,\n",
       "       4.306451612903226, 3.661290322580645, 2.4274193548387095, 1.0,\n",
       "       0.9435483870967742, 8.435483870967742, 11.85483870967742,\n",
       "       0.22580645161290322, 0.5161290322580645, 1.3951612903225807,\n",
       "       0.532258064516129, 0.7661290322580645, 81.44354838709677,\n",
       "       27.993200275468777, 14.18978102189781, 8.021897810218977,\n",
       "       3.7664233576642334, 6.1678832116788325, 0.2846715328467153,\n",
       "       0.24817518248175183, 33.91970802919708, 2.065693430656934,\n",
       "       1.0656934306569343, 1.9562043795620438, 2.335766423357664,\n",
       "       1.8832116788321167, 0.8905109489051095, 0.7956204379562044,\n",
       "       6.189781021897811, 7.956204379562044, 0.9124087591240876,\n",
       "       0.27007299270072993, 2.627737226277372, 0.021897810218978103,\n",
       "       0.3722627737226277, 85.94890510948905, 26.694953043146167,\n",
       "       16.917355371900825, 9.239669421487603, 3.024793388429752,\n",
       "       7.677685950413223, 0.32231404958677684, 0.34710743801652894,\n",
       "       0.049586776859504134, 3.8595041322314048, 1.6942148760330578,\n",
       "       2.8264462809917354, 1.3140495867768596, 1.9834710743801653,\n",
       "       0.7107438016528925, 0.7024793388429752, 5.661157024793388,\n",
       "       11.40495867768595, 0.14049586776859505, 0.17355371900826447,\n",
       "       1.2231404958677685, 0.9504132231404959, 0.38016528925619836,\n",
       "       78.0495867768595, 26.36142850184954, 13.339285714285714,\n",
       "       7.214285714285714, 4.321428571428571, 6.125, 0.5892857142857143,\n",
       "       0.21428571428571427, 0.7678571428571429, 2.3035714285714284,\n",
       "       1.3928571428571428, 1.4464285714285714, 0.42857142857142855,\n",
       "       1.5714285714285714, 0.6964285714285714, 0.6428571428571429,\n",
       "       4.928571428571429, 8.607142857142858, 0.8392857142857143, 0.625,\n",
       "       4.142857142857143, 0.08928571428571429, 0.35714285714285715,\n",
       "       85.21428571428571, 25.434862747743917, 23.53435114503817,\n",
       "       12.206106870229007, 4.358778625954199, 11.32824427480916,\n",
       "       0.6717557251908397, 0.35877862595419846, 0.648854961832061,\n",
       "       5.938931297709924, 1.4732824427480915, 4.114503816793893,\n",
       "       4.534351145038168, 2.595419847328244, 1.4732824427480915,\n",
       "       1.0076335877862594, 12.099236641221374, 11.770992366412214,\n",
       "       0.5877862595419847, 0.4198473282442748, 2.5267175572519083,\n",
       "       0.3511450381679389, 0.7022900763358778, 82.87786259541984,\n",
       "       24.745057228787715, 19.6171875, 12.3828125, 4.21875, 7.234375,\n",
       "       0.34375, 0.3359375, 0.03125, 1.859375, 3.7890625, 3.34375,\n",
       "       0.8828125, 2.2578125, 0.4921875, 0.5078125, 5.3828125, 13.0390625,\n",
       "       0.2890625, 0.125, 2.21875, 1.1640625, 0.3671875, 82.5078125,\n",
       "       22.98733889128456, 14.392523364485982, 10.177570093457945,\n",
       "       6.570093457943925, 4.214953271028038, 2.485981308411215,\n",
       "       1.6822429906542056, 0.028037383177570093, 1.560747663551402,\n",
       "       0.09345794392523364, 3.5046728971962615, 0.09345794392523364, 3.0,\n",
       "       0.9065420560747663, 1.3177570093457944, 6.420560747663552,\n",
       "       8.242990654205608, 1.5700934579439252, 2.7196261682242993,\n",
       "       1.3364485981308412, 0.08411214953271028, 1.0934579439252337,\n",
       "       89.6355140186916, 25.017740421979273, 26.336363636363636,\n",
       "       13.354545454545455, 3.7636363636363637, 12.981818181818182, 0.3,\n",
       "       0.34545454545454546, 0.14545454545454545, 5.4818181818181815,\n",
       "       1.4090909090909092, 3.9, 6.163636363636364, 3.918181818181818, 1.3,\n",
       "       1.8545454545454545, 12.481818181818182, 13.872727272727273,\n",
       "       0.2545454545454545, 0.24545454545454545, 1.1181818181818182,\n",
       "       0.02727272727272727, 0.4727272727272727, 83.96363636363637,\n",
       "       31.2333213238776, 17.92436974789916, 10.428571428571429,\n",
       "       3.957983193277311, 7.495798319327731, 0.8151260504201681,\n",
       "       0.3949579831932773, 0.0, 3.2436974789915967, 1.1176470588235294,\n",
       "       2.7394957983193278, 2.2184873949579833, 1.8991596638655461,\n",
       "       1.1680672268907564, 0.5378151260504201, 7.067226890756302,\n",
       "       10.630252100840336, 0.19327731092436976, 0.6554621848739496,\n",
       "       0.9327731092436975, 0.3697478991596639, 0.680672268907563,\n",
       "       81.15126050420169, 25.044279606337287, 27.248175182481752,\n",
       "       14.489051094890511, 4.197080291970803, 12.75912408759124,\n",
       "       1.167883211678832, 0.8686131386861314, 0.9124087591240876,\n",
       "       4.313868613138686, 1.3868613138686132, 5.642335766423358,\n",
       "       6.510948905109489, 3.510948905109489, 1.8686131386861313,\n",
       "       1.1240875912408759, 15.773722627737227, 11.89051094890511,\n",
       "       1.072992700729927, 0.8321167883211679, 1.3503649635036497,\n",
       "       0.7664233576642335, 0.635036496350365, 84.74452554744525,\n",
       "       24.718184184100465, 18.974025974025974, 11.688311688311689,\n",
       "       5.662337662337662, 7.285714285714286, 0.37662337662337664,\n",
       "       0.2857142857142857, 0.012987012987012988, 1.5194805194805194,\n",
       "       2.6623376623376624, 2.5064935064935066, 0.8831168831168831,\n",
       "       1.9610389610389611, 0.4155844155844156, 0.4025974025974026,\n",
       "       4.779220779220779, 13.857142857142858, 0.33766233766233766,\n",
       "       0.3116883116883117, 2.1298701298701297, 0.7272727272727273,\n",
       "       0.4025974025974026, 77.50649350649351, 26.400499436906752,\n",
       "       22.846774193548388, 15.040322580645162, 3.879032258064516,\n",
       "       7.806451612903226, 0.5080645161290323, 0.4435483870967742,\n",
       "       0.25806451612903225, 3.217741935483871, 2.5403225806451615,\n",
       "       3.3225806451612905, 3.6370967741935485, 2.903225806451613,\n",
       "       0.9596774193548387, 0.9919354838709677, 8.209677419354838,\n",
       "       14.274193548387096, 0.20161290322580644, 0.2661290322580645,\n",
       "       1.0161290322580645, 0.33064516129032256, 0.29838709677419356,\n",
       "       82.95967741935483, 29.18542629764097, 11.726315789473684,\n",
       "       7.063157894736842, 4.073684210526316, 4.663157894736842,\n",
       "       1.8526315789473684, 1.0842105263157895, 12.294736842105262,\n",
       "       2.2421052631578946, 0.23157894736842105, 1.7894736842105263,\n",
       "       1.3368421052631578, 2.1473684210526316, 1.2526315789473683,\n",
       "       1.263157894736842, 7.3052631578947365, 4.621052631578947,\n",
       "       1.8210526315789475, 2.0526315789473686, 2.0526315789473686,\n",
       "       0.010526315789473684, 0.43157894736842106, 79.46315789473684,\n",
       "       27.451293174722057, 16.71641791044776, 10.626865671641792,\n",
       "       3.91044776119403, 6.08955223880597, 0.373134328358209,\n",
       "       0.40298507462686567, 0.05970149253731343, 4.029850746268656,\n",
       "       1.5820895522388059, 2.91044776119403, 2.08955223880597,\n",
       "       2.5671641791044775, 0.7164179104477612, 1.0, 6.268656716417911,\n",
       "       10.044776119402986, 0.3582089552238806, 0.2835820895522388,\n",
       "       1.2238805970149254, 0.029850746268656716, 0.4925373134328358,\n",
       "       83.7910447761194, 27.403915554366407, 15.523809523809524,\n",
       "       9.619047619047619, 3.9285714285714284, 5.904761904761905,\n",
       "       1.0476190476190477, 0.6428571428571429, 0.07142857142857142,\n",
       "       2.3095238095238093, 0.7380952380952381, 2.4285714285714284,\n",
       "       1.6428571428571428, 2.238095238095238, 0.30952380952380953,\n",
       "       0.8333333333333334, 6.809523809523809, 8.523809523809524,\n",
       "       0.7619047619047619, 1.119047619047619, 1.119047619047619,\n",
       "       0.14285714285714285, 0.5952380952380952, 74.9047619047619,\n",
       "       28.109113416819945, 11.8, 6.0, 4.85, 5.8, 0.05,\n",
       "       0.03333333333333333, 0.08333333333333333, 1.4666666666666666, 1.65,\n",
       "       0.55, 0.2, 1.0833333333333333, 0.48333333333333334,\n",
       "       0.5833333333333334, 3.7666666666666666, 8.083333333333334,\n",
       "       0.5333333333333333, 0.016666666666666666, 3.7, 0.15, 0.05,\n",
       "       87.83333333333333, 29.871980031531564, 18.74468085106383,\n",
       "       12.851063829787234, 5.659574468085107, 5.8936170212765955,\n",
       "       0.0851063829787234, 0.06382978723404255, 0.0, 2.425531914893617,\n",
       "       3.2127659574468086, 1.4680851063829787, 0.851063829787234,\n",
       "       2.3191489361702127, 0.574468085106383, 1.0851063829787233,\n",
       "       5.787234042553192, 12.148936170212766, 0.8085106382978723,\n",
       "       0.06382978723404255, 2.404255319148936, 1.0212765957446808,\n",
       "       0.14893617021276595, 83.82978723404256, 29.248769288955355, 10.725,\n",
       "       6.375, 2.325, 4.35, 0.825, 0.7, 0.05, 4.175, 0.275, 1.925, 0.9,\n",
       "       1.625, 0.775, 0.7, 5.2, 5.175, 0.25, 0.625, 1.125, 0.275, 0.675,\n",
       "       75.825, 23.02066435313525, 9.88888888888889, 4.888888888888889,\n",
       "       2.888888888888889, 5.0, 0.0, 0.0, 0.0, 2.3333333333333335,\n",
       "       1.7777777777777777, 0.4444444444444444, 0.3333333333333333,\n",
       "       1.1111111111111112, 0.7777777777777778, 0.4444444444444444,\n",
       "       3.2222222222222223, 6.777777777777778, 0.3333333333333333, 0.0,\n",
       "       5.222222222222222, 0.6666666666666666, 0.0, 89.11111111111111,\n",
       "       22.842053947415454, 11.428571428571429, 8.047619047619047,\n",
       "       3.5714285714285716, 3.380952380952381, 1.0, 1.2380952380952381,\n",
       "       0.0, 2.4285714285714284, 1.1904761904761905, 1.9047619047619047,\n",
       "       0.47619047619047616, 1.7142857142857142, 0.9523809523809523,\n",
       "       0.7142857142857143, 4.095238095238095, 7.285714285714286,\n",
       "       0.23809523809523808, 0.8571428571428571, 1.0952380952380953,\n",
       "       0.09523809523809523, 0.23809523809523808, 75.9047619047619,\n",
       "       29.765221214737636, 12.448275862068966, 7.551724137931035,\n",
       "       2.8620689655172415, 4.896551724137931, 1.6206896551724137,\n",
       "       0.7931034482758621, 0.0, 1.7586206896551724, 0.3103448275862069,\n",
       "       2.2413793103448274, 0.7241379310344828, 1.6206896551724137,\n",
       "       0.5517241379310345, 0.6551724137931034, 5.517241379310345,\n",
       "       6.482758620689655, 0.3793103448275862, 1.103448275862069,\n",
       "       0.6551724137931034, 0.2413793103448276, 0.7931034482758621,\n",
       "       80.03448275862068, 29.739051499322724, 15.541666666666666,\n",
       "       8.583333333333334, 4.166666666666667, 6.958333333333333,\n",
       "       0.08333333333333333, 0.041666666666666664, 0.0, 3.0833333333333335,\n",
       "       1.9583333333333333, 1.2083333333333333, 0.8333333333333334,\n",
       "       1.4583333333333333, 0.875, 0.625, 5.5, 9.75, 0.2916666666666667,\n",
       "       0.0, 3.8333333333333335, 0.041666666666666664, 0.20833333333333334,\n",
       "       85.33333333333333, 32.895040053297926], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(X_train[0]))\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [0]*len(test)\n",
    "for i in range(0,len(test)):\n",
    "    player_list = []\n",
    "    j = 0\n",
    "    for j in range(0,len(player_stats_2018)):\n",
    "        if player_stats_2018[j][0] in test[i][-1]:\n",
    "            player_list.append(player_stats_2018[j][1:])\n",
    "    X_test[i] = player_list\n",
    "    \n",
    "X_test = [np.concatenate(x) for x in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "scaled_X_train = sc.fit_transform(X_train)\n",
    "scaled_X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "408"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train = np.hstack((scaled_X_train, opp_teams_train))\n",
    "scaled_X_test = np.hstack((scaled_X_test, opp_teams_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train = np.asarray(scaled_X_train).astype(np.float32)\n",
    "scaled_X_test = np.asarray(scaled_X_test).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.18809342e-01  1.21086979e+00 -6.62710309e-01  2.24780035e-03\n",
      " -1.99093353e-02  2.76421607e-01 -2.37170607e-01  5.80942214e-01\n",
      " -1.59369335e-01  1.61617553e+00  1.15693474e+00  4.88989621e-01\n",
      "  5.73852718e-01  5.92228711e-01  8.38677347e-01  3.50265175e-01\n",
      " -5.74591875e-01 -1.45324454e-01 -3.24574262e-01  1.82839751e-01\n",
      "  1.12314725e+00 -6.65854588e-02  1.48138237e+00 -4.98186707e-01\n",
      " -4.20792162e-01 -2.46276647e-01 -4.70008254e-01 -6.96794450e-01\n",
      " -6.69697583e-01  4.98701954e+00 -8.92397702e-01 -3.31930578e-01\n",
      " -4.39176649e-01  2.88001388e-01 -4.91637856e-01  8.16050619e-02\n",
      " -1.67277917e-01 -1.78655699e-01 -6.01860940e-01  8.02277267e-01\n",
      " -6.12190485e-01  3.75586897e-01 -9.59012747e-01 -3.23338598e-01\n",
      "  6.65037215e-01  6.78989708e-01 -1.08733557e-01 -2.03033388e-01\n",
      " -1.09663534e+00  5.59475785e-03 -6.64329171e-01 -4.20438260e-01\n",
      " -2.77306497e-01  5.41319668e-01  3.00944179e-01  1.83034271e-01\n",
      " -3.76473665e-01 -5.24111450e-01 -4.81638700e-01 -4.90642488e-01\n",
      " -4.64239508e-01  2.39514917e-01 -8.06424201e-01 -7.47153819e-01\n",
      " -4.89375085e-01  1.35540581e+00 -3.55426192e-01 -8.40888798e-01\n",
      "  7.14284003e-01 -9.15145695e-01 -1.06945467e+00  9.49373916e-02\n",
      " -5.97343147e-01 -1.59415156e-01 -7.55618632e-01 -1.35770440e-01\n",
      " -7.18832970e-01 -1.77933455e-01 -1.12887073e+00 -9.39356863e-01\n",
      " -1.30753911e+00 -5.06963849e-01 -6.70822501e-01 -8.35953534e-01\n",
      " -6.99106634e-01  6.53213382e-01  1.33452029e-03  1.52091658e+00\n",
      " -9.47467566e-01 -3.99624944e-01  3.54181796e-01  2.55315810e-01\n",
      "  1.03791142e+00  7.05284417e-01 -7.20451819e-04  1.07187605e+00\n",
      "  1.05098166e-01 -2.27530226e-01 -2.03575104e-01  2.39203715e+00\n",
      " -2.49277234e-01  1.58753002e+00  1.57932985e+00  7.31096625e-01\n",
      "  1.86989617e+00  7.76473284e-01  2.18377566e+00  1.51864633e-01\n",
      "  1.00950614e-01 -1.98011607e-01  2.35682294e-01 -9.86503884e-02\n",
      "  1.24439156e+00 -9.60637704e-02  3.11785620e-02  3.54700118e-01\n",
      "  8.37802410e-01 -1.48756444e-01 -1.73914433e-01 -4.94824469e-01\n",
      " -3.25564891e-01 -2.97642708e-01 -9.70727980e-01  2.31481767e+00\n",
      "  8.27246070e-01 -5.93910754e-01  4.50896621e-02 -1.23847091e+00\n",
      " -1.17095256e+00 -6.27734900e-01  6.32392526e-01 -5.64945579e-01\n",
      " -6.71717346e-01 -6.55303448e-02  2.43165851e+00 -2.62087286e-01\n",
      " -2.59956449e-01 -6.74652100e-01 -6.80006504e-01  5.99085949e-02\n",
      "  1.85188627e+00 -1.17036116e+00  2.88822389e+00  3.42196655e+00\n",
      " -2.72375733e-01 -1.19871175e+00 -1.64348304e+00  1.00260067e+00\n",
      " -9.99738455e-01  1.57358468e+00  1.44186825e-01  1.87392402e+00\n",
      " -1.39216766e-01 -8.02510619e-01  2.41130853e+00  3.08959126e+00\n",
      " -5.20521045e-01 -7.49287367e-01  2.83290648e+00  1.10346174e+00\n",
      "  8.93063471e-02  1.71149230e+00  1.20727861e+00 -3.86529356e-01\n",
      "  1.68486488e+00 -5.29982090e-01 -2.53453553e-01 -2.68454850e-01\n",
      "  1.82692695e+00 -2.44144395e-01  1.35119069e+00  2.38991880e+00\n",
      "  3.28572750e+00  1.23965359e+00  3.48989034e+00  2.19257092e+00\n",
      "  8.64397168e-01 -5.27735114e-01 -4.70198125e-01 -6.11749589e-01\n",
      " -8.11892033e-01  2.36427635e-01  2.03139991e-01  2.16039371e+00\n",
      "  2.07484141e-02  1.72180429e-01 -2.21961781e-01 -1.29297227e-01\n",
      "  4.67381090e-01 -1.68542136e-02 -3.01787615e-01  9.79537591e-02\n",
      " -5.59098065e-01  2.79815882e-01  1.88389331e-01 -6.65618360e-01\n",
      "  7.55025625e-01 -8.96841109e-01  1.20444901e-01 -1.01462148e-01\n",
      " -6.72019958e-01  2.83885539e-01 -7.53802180e-01 -1.19006850e-01\n",
      "  1.24774337e+00 -2.52997905e-01  1.09781019e-01  1.96399653e+00\n",
      "  1.51530802e+00 -1.55969232e-03  1.77988350e+00  1.11337280e+00\n",
      "  1.47838926e+00 -9.73054469e-02  9.45152462e-01 -3.12535644e-01\n",
      "  3.05320358e+00  2.84112144e+00  2.14351583e+00  2.72312903e+00\n",
      "  8.57011676e-01  3.74905396e+00  2.78833747e-01  1.29950941e+00\n",
      "  6.28301919e-01 -4.84864861e-01  5.06910026e-01  1.03947079e+00\n",
      "  3.81613821e-01  2.98698507e-02  3.15029025e-01  6.38361812e-01\n",
      "  1.26557577e+00 -9.41230133e-02 -3.84911418e-01 -3.88186306e-01\n",
      " -2.58880347e-01 -1.27290034e+00  9.10921216e-01  8.72308910e-02\n",
      " -5.37169218e-01 -4.88399804e-01 -1.18053830e+00 -1.35845160e+00\n",
      " -7.61122465e-01  9.45534289e-01 -3.42839777e-01 -3.28653872e-01\n",
      " -5.28588034e-02  5.16758680e-01 -4.43884246e-02 -8.65342379e-01\n",
      "  5.01841247e-01  1.26850116e+00  2.03497577e+00 -2.16073632e-01\n",
      "  1.58334047e-01 -1.73155040e-01  4.35282402e-02 -2.02439979e-01\n",
      "  5.99664897e-02  8.56520116e-01  1.00162184e+00  1.08744943e+00\n",
      "  1.17143393e+00  2.41715342e-01  4.45099831e-01  6.72199845e-01\n",
      "  1.30446565e+00 -6.78817987e-01 -4.31898713e-01 -7.22849786e-01\n",
      " -1.82296962e-01 -4.71794963e-01  5.75136542e-02  1.33124435e+00\n",
      " -1.09253228e+00 -9.34656680e-01  9.10455268e-03 -9.32466984e-01\n",
      "  2.12812710e+00  1.82384002e+00  1.87811649e+00 -7.01019287e-01\n",
      " -1.28776813e+00 -6.23073697e-01 -2.66670108e-01 -1.33478135e-01\n",
      "  1.04988933e+00  1.28187716e+00  3.54107767e-01 -1.79108167e+00\n",
      "  2.82507730e+00  2.29449201e+00 -3.00438739e-02 -8.48353028e-01\n",
      "  1.22690238e-01 -4.08859640e-01  8.17928791e-01  5.84636927e-02\n",
      "  5.00973165e-01 -6.76964223e-02 -3.80370498e-01 -3.86969060e-01\n",
      " -2.83601284e-02 -2.82783210e-01  7.78618097e-01  7.54626235e-03\n",
      "  6.12640321e-01  2.33642355e-01  7.03894377e-01 -3.12508523e-01\n",
      "  4.99834955e-01 -1.21385315e-02 -7.82594923e-03 -2.96932131e-01\n",
      " -3.84998113e-01 -5.79293132e-01 -7.94609487e-01  5.11222303e-01\n",
      "  3.49591911e-01  7.96355426e-01 -1.60543516e-01  1.52830601e-01\n",
      " -6.41966239e-02 -4.42849517e-01  9.76986885e-01  7.60697603e-01\n",
      " -2.91233301e-01 -5.99036932e-01 -8.24669003e-01  1.38620377e-01\n",
      "  4.32913471e-03  1.75500378e-01 -1.43529820e+00  3.88624221e-02\n",
      "  2.94949979e-01 -4.73004699e-01  6.88009143e-01  1.17498386e+00\n",
      " -6.31863892e-01 -6.28557086e-01  1.01856613e+00 -9.58716094e-01\n",
      "  9.17191684e-01 -9.22951996e-01 -1.15699208e+00  7.85757959e-01\n",
      " -4.61614698e-01 -9.82222319e-01 -1.12078905e+00 -3.13614756e-01\n",
      " -1.33208513e+00  1.20142996e-01 -1.75966787e+00 -9.35109794e-01\n",
      " -1.94708025e+00 -9.11858261e-01 -7.84181118e-01 -1.07433367e+00\n",
      " -5.71896970e-01  8.37616548e-02 -8.77766132e-01  1.04624820e+00\n",
      " -5.57133615e-01 -1.52711546e+00  9.47948515e-01  1.25768387e+00\n",
      "  6.63876891e-01  1.45668566e+00  1.61917055e+00 -3.44850332e-01\n",
      " -8.66941869e-01 -1.00954258e+00 -3.19771409e-01 -3.66287142e-01\n",
      "  1.68424702e+00 -6.82577670e-01 -4.42206383e-01  4.91066098e-01\n",
      " -5.97313344e-01  8.90743792e-01 -4.68898304e-02  7.66392231e-01\n",
      "  8.36656094e-01 -7.58020818e-01  8.69255960e-02  1.57544267e+00\n",
      " -9.34229076e-01  3.52214277e-01  1.06166518e+00 -1.06943905e+00\n",
      " -9.25110459e-01 -1.46190536e+00 -9.34480667e-01  6.34586930e-01\n",
      "  1.10466993e+00 -3.05785090e-01  1.24184716e+00 -1.24654675e+00\n",
      " -2.09857151e-01 -4.09569561e-01 -8.66403699e-01 -3.68366502e-02\n",
      " -3.47393632e-01 -3.14555168e-01 -1.41187418e+00 -5.35260141e-01\n",
      "  2.82600611e-01 -6.69407010e-01 -1.96893081e-01  1.43283808e+00\n",
      " -6.19865835e-01 -6.12019181e-01 -1.17982244e+00 -1.38390028e+00\n",
      " -8.65662694e-01 -6.52515292e-01 -1.04944706e+00 -1.28700316e+00\n",
      " -3.16383958e-01 -4.58456516e-01  3.16194475e-01 -1.77054107e+00\n",
      " -8.15119863e-01 -1.79344869e+00 -1.31525332e-02 -1.18237412e+00\n",
      " -1.27040887e+00 -8.11834335e-01 -2.81072706e-01 -9.17711258e-01\n",
      "  1.95997989e+00  7.15140104e-01 -1.60352027e+00  1.14714456e+00\n",
      " -6.62878931e-01 -7.99647987e-01 -1.56083405e-01 -2.19125345e-01\n",
      " -1.26597691e+00  1.04376924e+00  2.94918466e+00 -3.38873804e-01\n",
      " -2.99597085e-01 -2.37962097e-01 -1.76177606e-01 -7.05588639e-01\n",
      " -6.17885590e-01  5.51392317e-01 -3.37058365e-01 -8.14433217e-01\n",
      " -6.07588887e-01 -5.46337366e-01  8.42047930e-01 -6.88188255e-01\n",
      " -5.76614976e-01 -5.12049258e-01 -4.63523060e-01  9.65665281e-01\n",
      " -5.05438507e-01 -2.36384392e-01 -7.33447194e-01 -6.46196365e-01\n",
      "  2.60041451e+00  1.61951101e+00 -3.57517213e-01 -9.00337160e-01\n",
      " -1.10027158e+00  3.51614416e-01 -4.97649789e-01 -7.66390979e-01\n",
      " -5.74428439e-01 -5.50410688e-01 -4.00047265e-02 -7.68099248e-01\n",
      " -1.89622253e-01  1.45644569e+00 -1.01471508e+00 -1.62530452e-01\n",
      "  2.18984699e+00  9.65666994e-02  9.71695244e-01  4.19559240e-01\n",
      "  3.09390545e-01  4.33540970e-01  4.11357999e-01 -7.77150095e-01\n",
      " -9.26977694e-01 -3.57425928e-01  4.27528560e-01  5.64538598e-01\n",
      " -6.54419780e-01 -3.11623454e-01 -7.99111068e-01  4.51580852e-01\n",
      " -5.04209042e-01  1.10558040e-01  4.26796496e-01 -3.59203190e-01\n",
      " -8.57571423e-01  1.07125640e+00 -6.18961513e-01 -4.37407762e-01\n",
      "  6.69915140e-01  1.72120297e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "print(scaled_X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the ANN\n",
    "ann = tf.keras.models.Sequential()\n",
    "# First layer\n",
    "ann.add(tf.keras.layers.Dense(units = 4, activation = 'relu'))\n",
    "# Second layer\n",
    "ann.add(tf.keras.layers.Dense(units = 4, activation = 'relu'))\n",
    "# Output layer\n",
    "ann.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 0s 677us/step - loss: 0.7079 - accuracy: 0.5288\n",
      "78/78 [==============================] - 0s 447us/step - loss: 0.6613 - accuracy: 0.6091\n",
      "13/13 [==============================] - 0s 537us/step - loss: 0.6812 - accuracy: 0.5711\n",
      "78/78 [==============================] - 0s 767us/step - loss: 0.6588 - accuracy: 0.6156\n",
      "78/78 [==============================] - 0s 524us/step - loss: 0.6351 - accuracy: 0.6675\n",
      "13/13 [==============================] - 0s 613us/step - loss: 0.6710 - accuracy: 0.6005\n",
      "78/78 [==============================] - 0s 741us/step - loss: 0.6349 - accuracy: 0.6590\n",
      "78/78 [==============================] - 0s 498us/step - loss: 0.6094 - accuracy: 0.7048\n",
      "13/13 [==============================] - 0s 613us/step - loss: 0.6672 - accuracy: 0.6225\n",
      "78/78 [==============================] - 0s 702us/step - loss: 0.6114 - accuracy: 0.6890\n",
      "78/78 [==============================] - 0s 511us/step - loss: 0.5833 - accuracy: 0.7149\n",
      "13/13 [==============================] - 0s 614us/step - loss: 0.6636 - accuracy: 0.6250\n",
      "78/78 [==============================] - 0s 690us/step - loss: 0.5903 - accuracy: 0.6959\n",
      "78/78 [==============================] - 0s 486us/step - loss: 0.5607 - accuracy: 0.7271\n",
      "13/13 [==============================] - 0s 613us/step - loss: 0.6641 - accuracy: 0.6348\n",
      "78/78 [==============================] - 0s 869us/step - loss: 0.5684 - accuracy: 0.7137\n",
      "78/78 [==============================] - 0s 460us/step - loss: 0.5383 - accuracy: 0.7457\n",
      "13/13 [==============================] - 0s 537us/step - loss: 0.6651 - accuracy: 0.6078\n",
      "78/78 [==============================] - 0s 728us/step - loss: 0.5510 - accuracy: 0.7307\n",
      "78/78 [==============================] - 0s 703us/step - loss: 0.5204 - accuracy: 0.7547\n",
      "13/13 [==============================] - 0s 614us/step - loss: 0.6597 - accuracy: 0.6201\n",
      "78/78 [==============================] - 0s 767us/step - loss: 0.5305 - accuracy: 0.7360\n",
      "78/78 [==============================] - 0s 486us/step - loss: 0.5005 - accuracy: 0.7737\n",
      "13/13 [==============================] - 0s 613us/step - loss: 0.6671 - accuracy: 0.6005\n",
      "78/78 [==============================] - 0s 767us/step - loss: 0.5129 - accuracy: 0.7539\n",
      "78/78 [==============================] - 0s 473us/step - loss: 0.4850 - accuracy: 0.7871\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6419 - accuracy: 0.6250WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "13/13 [==============================] - 0s 613us/step - loss: 0.6728 - accuracy: 0.6103\n",
      "78/78 [==============================] - 0s 792us/step - loss: 0.4984 - accuracy: 0.7705\n",
      "78/78 [==============================] - 0s 498us/step - loss: 0.4668 - accuracy: 0.7956\n",
      "13/13 [==============================] - 0s 767us/step - loss: 0.6837 - accuracy: 0.5882\n",
      "78/78 [==============================] - 0s 754us/step - loss: 0.4807 - accuracy: 0.7810\n",
      "78/78 [==============================] - 0s 498us/step - loss: 0.4513 - accuracy: 0.8070\n",
      "13/13 [==============================] - 0s 766us/step - loss: 0.6896 - accuracy: 0.5907\n",
      "78/78 [==============================] - 0s 767us/step - loss: 0.4690 - accuracy: 0.7899\n",
      "78/78 [==============================] - 0s 639us/step - loss: 0.4382 - accuracy: 0.8167\n",
      "13/13 [==============================] - 0s 613us/step - loss: 0.7003 - accuracy: 0.5931\n",
      "78/78 [==============================] - 0s 767us/step - loss: 0.4546 - accuracy: 0.8009\n",
      "78/78 [==============================] - 0s 562us/step - loss: 0.4221 - accuracy: 0.8232\n",
      "13/13 [==============================] - 0s 843us/step - loss: 0.7152 - accuracy: 0.5711\n",
      " 1/78 [..............................] - ETA: 0s - loss: 0.3730 - accuracy: 0.8750WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "78/78 [==============================] - 0s 856us/step - loss: 0.4442 - accuracy: 0.8017\n",
      "78/78 [==============================] - 0s 511us/step - loss: 0.4128 - accuracy: 0.8297\n",
      "13/13 [==============================] - 0s 767us/step - loss: 0.7172 - accuracy: 0.5735\n",
      "78/78 [==============================] - 0s 741us/step - loss: 0.4265 - accuracy: 0.8135\n",
      "78/78 [==============================] - 0s 549us/step - loss: 0.3952 - accuracy: 0.8354\n",
      "13/13 [==============================] - 0s 613us/step - loss: 0.7335 - accuracy: 0.5809\n",
      "78/78 [==============================] - 0s 716us/step - loss: 0.4160 - accuracy: 0.8179\n",
      "78/78 [==============================] - 0s 473us/step - loss: 0.3844 - accuracy: 0.8467\n",
      "13/13 [==============================] - 0s 690us/step - loss: 0.7524 - accuracy: 0.5735\n",
      "78/78 [==============================] - 0s 818us/step - loss: 0.4035 - accuracy: 0.8293\n",
      " 1/78 [..............................] - ETA: 0s - loss: 0.4375 - accuracy: 0.8438WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "78/78 [==============================] - 0s 690us/step - loss: 0.3687 - accuracy: 0.8528\n",
      "13/13 [==============================] - 0s 690us/step - loss: 0.7575 - accuracy: 0.5931\n",
      "78/78 [==============================] - 0s 818us/step - loss: 0.3916 - accuracy: 0.8350\n",
      "78/78 [==============================] - 0s 549us/step - loss: 0.3606 - accuracy: 0.8577\n",
      "13/13 [==============================] - 0s 613us/step - loss: 0.7714 - accuracy: 0.6054\n",
      "78/78 [==============================] - 0s 754us/step - loss: 0.3805 - accuracy: 0.8378\n",
      "78/78 [==============================] - 0s 601us/step - loss: 0.3487 - accuracy: 0.8601\n",
      "13/13 [==============================] - 0s 614us/step - loss: 0.7834 - accuracy: 0.5931\n",
      "78/78 [==============================] - 0s 754us/step - loss: 0.3685 - accuracy: 0.8455\n",
      "78/78 [==============================] - 0s 498us/step - loss: 0.3376 - accuracy: 0.8723\n",
      "13/13 [==============================] - 0s 690us/step - loss: 0.8033 - accuracy: 0.5931\n",
      "78/78 [==============================] - 0s 818us/step - loss: 0.3564 - accuracy: 0.8528\n",
      "78/78 [==============================] - 0s 626us/step - loss: 0.3265 - accuracy: 0.8759\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.7926 - accuracy: 0.5625WARNING:tensorflow:Callbacks method `on_test_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "13/13 [==============================] - 0s 690us/step - loss: 0.8246 - accuracy: 0.6029\n",
      "78/78 [==============================] - 0s 831us/step - loss: 0.3463 - accuracy: 0.8573\n",
      "78/78 [==============================] - 0s 549us/step - loss: 0.3183 - accuracy: 0.8832\n",
      "13/13 [==============================] - 0s 690us/step - loss: 0.8335 - accuracy: 0.6005\n",
      "78/78 [==============================] - 0s 754us/step - loss: 0.3401 - accuracy: 0.8577\n",
      "78/78 [==============================] - 0s 498us/step - loss: 0.3113 - accuracy: 0.8828\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.8333 - accuracy: 0.5312WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "13/13 [==============================] - 0s 844us/step - loss: 0.8499 - accuracy: 0.5956\n",
      "78/78 [==============================] - 0s 716us/step - loss: 0.3291 - accuracy: 0.8694\n",
      "78/78 [==============================] - 0s 537us/step - loss: 0.2998 - accuracy: 0.8877\n",
      "13/13 [==============================] - 0s 613us/step - loss: 0.8728 - accuracy: 0.5882\n",
      "78/78 [==============================] - 0s 741us/step - loss: 0.3187 - accuracy: 0.8678\n",
      "78/78 [==============================] - 0s 562us/step - loss: 0.2919 - accuracy: 0.8938\n",
      "13/13 [==============================] - 0s 537us/step - loss: 0.8956 - accuracy: 0.5809\n"
     ]
    }
   ],
   "source": [
    "steps = []\n",
    "accs = []\n",
    "test_accs = []\n",
    "\n",
    "for i in range(0, 25):\n",
    "    ann.fit(scaled_X_train, y_train, epochs = 1)\n",
    "    [loss, accuracy] = ann.evaluate(scaled_X_train, y_train)\n",
    "    [loss_t, accuracy_t] = ann.evaluate(scaled_X_test, y_test)\n",
    "    accs.append(accuracy), steps.append(i), test_accs.append(accuracy_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2028ab52808>]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(steps, accs)\n",
    "plt.plot(steps, test_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ann.predict(scaled_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6913418 ],\n",
       "       [0.44829708],\n",
       "       [0.59492993],\n",
       "       [0.65300065],\n",
       "       [0.4223319 ],\n",
       "       [0.4143241 ],\n",
       "       [0.15169099],\n",
       "       [0.41322654],\n",
       "       [0.05673802],\n",
       "       [0.21605965],\n",
       "       [0.7085784 ],\n",
       "       [0.03070465],\n",
       "       [0.2955696 ],\n",
       "       [0.00478819],\n",
       "       [0.00337926],\n",
       "       [0.3259145 ],\n",
       "       [0.33356506],\n",
       "       [0.3282336 ],\n",
       "       [0.27411434],\n",
       "       [0.33356506],\n",
       "       [0.43759742],\n",
       "       [0.16658884],\n",
       "       [0.9472754 ],\n",
       "       [0.489399  ],\n",
       "       [0.8749249 ],\n",
       "       [0.981809  ],\n",
       "       [0.9689517 ],\n",
       "       [0.34634256],\n",
       "       [0.13662866],\n",
       "       [0.611145  ],\n",
       "       [0.45109048],\n",
       "       [0.9599432 ],\n",
       "       [0.45901597],\n",
       "       [0.4377189 ],\n",
       "       [0.6704484 ],\n",
       "       [0.6435526 ],\n",
       "       [0.9982467 ],\n",
       "       [0.44827214],\n",
       "       [0.31795084],\n",
       "       [0.7852206 ],\n",
       "       [0.83350784],\n",
       "       [0.4675299 ],\n",
       "       [0.45109048],\n",
       "       [0.53066957],\n",
       "       [0.971976  ],\n",
       "       [0.998333  ],\n",
       "       [0.9995004 ],\n",
       "       [0.97146374],\n",
       "       [0.965087  ],\n",
       "       [0.9850298 ],\n",
       "       [0.78921837],\n",
       "       [0.9925246 ],\n",
       "       [0.95457375],\n",
       "       [0.4609402 ],\n",
       "       [0.9919574 ],\n",
       "       [0.46780315],\n",
       "       [0.9342031 ],\n",
       "       [0.4820734 ],\n",
       "       [0.86538947],\n",
       "       [0.9581404 ],\n",
       "       [0.9937988 ],\n",
       "       [0.9627046 ],\n",
       "       [0.9361926 ],\n",
       "       [0.99244547],\n",
       "       [0.9849652 ],\n",
       "       [0.8645247 ],\n",
       "       [0.7703137 ],\n",
       "       [0.71779895],\n",
       "       [0.33356506],\n",
       "       [0.26036656],\n",
       "       [0.55161226],\n",
       "       [0.19480324],\n",
       "       [0.29777277],\n",
       "       [0.5571137 ],\n",
       "       [0.81862587],\n",
       "       [0.9990666 ],\n",
       "       [0.99573576],\n",
       "       [0.942348  ],\n",
       "       [0.33356506],\n",
       "       [0.9756304 ],\n",
       "       [0.36672693],\n",
       "       [0.8189409 ],\n",
       "       [0.827549  ],\n",
       "       [0.33356506],\n",
       "       [0.33356506],\n",
       "       [0.33356506],\n",
       "       [0.92402136],\n",
       "       [0.66072845],\n",
       "       [0.84532595],\n",
       "       [0.6664232 ],\n",
       "       [0.6266978 ],\n",
       "       [0.21206012],\n",
       "       [0.5395114 ],\n",
       "       [0.01789513],\n",
       "       [0.04891795],\n",
       "       [0.1717357 ],\n",
       "       [0.08679238],\n",
       "       [0.00523531],\n",
       "       [0.18463182],\n",
       "       [0.38264304],\n",
       "       [0.2868482 ],\n",
       "       [0.2602882 ],\n",
       "       [0.0435631 ],\n",
       "       [0.00504795],\n",
       "       [0.38625935],\n",
       "       [0.6408234 ],\n",
       "       [0.33356506],\n",
       "       [0.33356506],\n",
       "       [0.33356506],\n",
       "       [0.40180945],\n",
       "       [0.01686895],\n",
       "       [0.5643906 ],\n",
       "       [0.9640859 ],\n",
       "       [0.97587615],\n",
       "       [0.996446  ],\n",
       "       [0.65617293],\n",
       "       [0.916435  ],\n",
       "       [0.9909894 ],\n",
       "       [0.89450896],\n",
       "       [0.45109048],\n",
       "       [0.45109048],\n",
       "       [0.97404706],\n",
       "       [0.90431476],\n",
       "       [0.96830577],\n",
       "       [0.51586986],\n",
       "       [0.20477828],\n",
       "       [0.7146765 ],\n",
       "       [0.07394218],\n",
       "       [0.6026356 ],\n",
       "       [0.28908026],\n",
       "       [0.5934148 ],\n",
       "       [0.95752007],\n",
       "       [0.8319868 ],\n",
       "       [0.98055094],\n",
       "       [0.99969363],\n",
       "       [0.62707984],\n",
       "       [0.45109048],\n",
       "       [0.48138022],\n",
       "       [0.45109048],\n",
       "       [0.08672851],\n",
       "       [0.31336462],\n",
       "       [0.80584395],\n",
       "       [0.45109048],\n",
       "       [0.18878976],\n",
       "       [0.29282862],\n",
       "       [0.42785025],\n",
       "       [0.44075736],\n",
       "       [0.45109048],\n",
       "       [0.03065869],\n",
       "       [0.33356506],\n",
       "       [0.8753978 ],\n",
       "       [0.02903116],\n",
       "       [0.5469282 ],\n",
       "       [0.45776257],\n",
       "       [0.44274917],\n",
       "       [0.88509417],\n",
       "       [0.72277963],\n",
       "       [0.33356506],\n",
       "       [0.9542088 ],\n",
       "       [0.5576704 ],\n",
       "       [0.94533193],\n",
       "       [0.65646213],\n",
       "       [0.94066036],\n",
       "       [0.9534105 ],\n",
       "       [0.86689484],\n",
       "       [0.9910144 ],\n",
       "       [0.88985646],\n",
       "       [0.33356506],\n",
       "       [0.98999035],\n",
       "       [0.81734395],\n",
       "       [0.33356506],\n",
       "       [0.94990337],\n",
       "       [0.6838583 ],\n",
       "       [0.33356506],\n",
       "       [0.610725  ],\n",
       "       [0.91229624],\n",
       "       [0.72982013],\n",
       "       [0.45109048],\n",
       "       [0.9791632 ],\n",
       "       [0.1927549 ],\n",
       "       [0.13372788],\n",
       "       [0.35311592],\n",
       "       [0.29011327],\n",
       "       [0.0823642 ],\n",
       "       [0.04350635],\n",
       "       [0.28275043],\n",
       "       [0.8848494 ],\n",
       "       [0.9000553 ],\n",
       "       [0.987422  ],\n",
       "       [0.8094102 ],\n",
       "       [0.45109048],\n",
       "       [0.129596  ],\n",
       "       [0.18317491],\n",
       "       [0.21229523],\n",
       "       [0.40507594],\n",
       "       [0.37837952],\n",
       "       [0.33034724],\n",
       "       [0.29236728],\n",
       "       [0.9528475 ],\n",
       "       [0.40491647],\n",
       "       [0.7808126 ],\n",
       "       [0.31623435],\n",
       "       [0.8954629 ],\n",
       "       [0.8024962 ],\n",
       "       [0.8776778 ],\n",
       "       [0.4322594 ],\n",
       "       [0.72206414],\n",
       "       [0.78566   ],\n",
       "       [0.32619393],\n",
       "       [0.09219214],\n",
       "       [0.05166319],\n",
       "       [0.06536138],\n",
       "       [0.12104574],\n",
       "       [0.7714265 ],\n",
       "       [0.17200872],\n",
       "       [0.93449897],\n",
       "       [0.7262565 ],\n",
       "       [0.512444  ],\n",
       "       [0.9064319 ],\n",
       "       [0.10888505],\n",
       "       [0.9705434 ],\n",
       "       [0.90590405],\n",
       "       [0.5521527 ],\n",
       "       [0.9166872 ],\n",
       "       [0.33356506],\n",
       "       [0.8130363 ],\n",
       "       [0.42842498],\n",
       "       [0.87207866],\n",
       "       [0.0657886 ],\n",
       "       [0.05450159],\n",
       "       [0.05892989],\n",
       "       [0.09083045],\n",
       "       [0.03251073],\n",
       "       [0.33356506],\n",
       "       [0.44156393],\n",
       "       [0.22285402],\n",
       "       [0.17950541],\n",
       "       [0.26856458],\n",
       "       [0.33356506],\n",
       "       [0.29908866],\n",
       "       [0.09922129],\n",
       "       [0.44591314],\n",
       "       [0.35115403],\n",
       "       [0.36658272],\n",
       "       [0.45109048],\n",
       "       [0.06307402],\n",
       "       [0.06486088],\n",
       "       [0.19813389],\n",
       "       [0.08627695],\n",
       "       [0.16679496],\n",
       "       [0.10560101],\n",
       "       [0.13233635],\n",
       "       [0.33356506],\n",
       "       [0.93239987],\n",
       "       [0.40189302],\n",
       "       [0.09286469],\n",
       "       [0.13520306],\n",
       "       [0.7083865 ],\n",
       "       [0.38949096],\n",
       "       [0.77384126],\n",
       "       [0.10103807],\n",
       "       [0.14863977],\n",
       "       [0.34784508],\n",
       "       [0.15851107],\n",
       "       [0.08009452],\n",
       "       [0.02698365],\n",
       "       [0.11873668],\n",
       "       [0.45109048],\n",
       "       [0.50971866],\n",
       "       [0.5934018 ],\n",
       "       [0.1868681 ],\n",
       "       [0.16251454],\n",
       "       [0.29180083],\n",
       "       [0.94504786],\n",
       "       [0.92903775],\n",
       "       [0.9714496 ],\n",
       "       [0.3347656 ],\n",
       "       [0.04955557],\n",
       "       [0.6440014 ],\n",
       "       [0.9702383 ],\n",
       "       [0.33253786],\n",
       "       [0.55054903],\n",
       "       [0.37233546],\n",
       "       [0.7318123 ],\n",
       "       [0.36608538],\n",
       "       [0.5080257 ],\n",
       "       [0.39786178],\n",
       "       [0.19808504],\n",
       "       [0.08876148],\n",
       "       [0.72910357],\n",
       "       [0.21615484],\n",
       "       [0.6668676 ],\n",
       "       [0.91222477],\n",
       "       [0.8240322 ],\n",
       "       [0.33356506],\n",
       "       [0.35102916],\n",
       "       [0.49726647],\n",
       "       [0.45109048],\n",
       "       [0.37749022],\n",
       "       [0.45109048],\n",
       "       [0.34885943],\n",
       "       [0.70252466],\n",
       "       [0.79894364],\n",
       "       [0.45109048],\n",
       "       [0.34818822],\n",
       "       [0.22713912],\n",
       "       [0.9478121 ],\n",
       "       [0.72685987],\n",
       "       [0.31243235],\n",
       "       [0.4941883 ],\n",
       "       [0.49045518],\n",
       "       [0.30583632],\n",
       "       [0.06889334],\n",
       "       [0.33356506],\n",
       "       [0.44959125],\n",
       "       [0.14243957],\n",
       "       [0.37110806],\n",
       "       [0.4493348 ],\n",
       "       [0.16854995],\n",
       "       [0.7763623 ],\n",
       "       [0.82933056],\n",
       "       [0.37132692],\n",
       "       [0.3881459 ],\n",
       "       [0.20505148],\n",
       "       [0.5583529 ],\n",
       "       [0.5928237 ],\n",
       "       [0.5969875 ],\n",
       "       [0.17808667],\n",
       "       [0.2991845 ],\n",
       "       [0.04204866],\n",
       "       [0.10372689],\n",
       "       [0.6981084 ],\n",
       "       [0.4184674 ],\n",
       "       [0.94403005],\n",
       "       [0.9464925 ],\n",
       "       [0.78317654],\n",
       "       [0.00119779],\n",
       "       [0.44645345],\n",
       "       [0.19655293],\n",
       "       [0.05977464],\n",
       "       [0.765599  ],\n",
       "       [0.15547204],\n",
       "       [0.31357414],\n",
       "       [0.43792617],\n",
       "       [0.14413017],\n",
       "       [0.21300429],\n",
       "       [0.84718704],\n",
       "       [0.46050024],\n",
       "       [0.45109048],\n",
       "       [0.35056794],\n",
       "       [0.31669897],\n",
       "       [0.16005778],\n",
       "       [0.12007225],\n",
       "       [0.23006025],\n",
       "       [0.9876506 ],\n",
       "       [0.06436127],\n",
       "       [0.03077683],\n",
       "       [0.04625681],\n",
       "       [0.9461595 ],\n",
       "       [0.3508867 ],\n",
       "       [0.50772375],\n",
       "       [0.23013064],\n",
       "       [0.45109048],\n",
       "       [0.2526622 ],\n",
       "       [0.5325598 ],\n",
       "       [0.45109048],\n",
       "       [0.4384552 ],\n",
       "       [0.87763023],\n",
       "       [0.68361676],\n",
       "       [0.33356506],\n",
       "       [0.45318747],\n",
       "       [0.6903082 ],\n",
       "       [0.59874046],\n",
       "       [0.82432944],\n",
       "       [0.1041829 ],\n",
       "       [0.5483449 ],\n",
       "       [0.47774944],\n",
       "       [0.45069548],\n",
       "       [0.33356506],\n",
       "       [0.79374844],\n",
       "       [0.45109048],\n",
       "       [0.33356506],\n",
       "       [0.57245576],\n",
       "       [0.50918764],\n",
       "       [0.21637556],\n",
       "       [0.45109048],\n",
       "       [0.12387538],\n",
       "       [0.9247571 ],\n",
       "       [0.3660185 ],\n",
       "       [0.75428617],\n",
       "       [0.4087574 ],\n",
       "       [0.8811384 ],\n",
       "       [0.9990603 ],\n",
       "       [0.96713424],\n",
       "       [0.9977243 ],\n",
       "       [0.803832  ],\n",
       "       [0.7585108 ],\n",
       "       [0.44558537],\n",
       "       [0.9825443 ],\n",
       "       [0.41794986],\n",
       "       [0.43163678],\n",
       "       [0.9506711 ],\n",
       "       [0.99347126],\n",
       "       [0.9116277 ],\n",
       "       [0.7262196 ],\n",
       "       [0.7599622 ],\n",
       "       [0.6487226 ],\n",
       "       [0.62164044]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = [1 if x>=0.5 else 0 for x in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5980392156862745\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test,y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
